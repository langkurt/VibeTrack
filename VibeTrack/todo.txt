# VibeTrack TODO List

## High Priority

- additional way to navigate app. swipe gesture beteen views. so you can move from track view to enties view by swiping the screen from right to left.

## Medium Priority
- reserach task. Semantic caching for responses - Users will most likely eat the same things multiple times. Need to design this to flesh out the idea. There are a couple papers worth reading on this because semantic caching is storing the user's intent not just the hashed input verbatim. So "avocado toast" and "toast with avocado" are both the same and a cache hit. Anthropic has prompt caching, but is invalidated after 5 minutes. I would rather have something like a two-layer space-constrained cache. L1 would be smaller and per user, and L2 would be app-wide and larger. If both miss, then I guess go ask the LLM :)

- Cloud storage for user data/telemetry - Need to set up a cloud solution for receiving and analyzing telemetry. User I/O, failure rate, edit rate, user sentiment (frustrated, etc). Considering Azure Event Hubs and Service Bus since I have some Azure credits to use. Building it out with some Bicep declarative IaC would be good. Give instructions on setting this up with azure, i dont remember how to do it. I have 150 dollar credit per month to play with.

- Store input/output for AI responses - Evaluate those and make sure they are not deviating. Create the curated dataset based on if they are good or not, then train the SLM to check all responses and report success metrics. Can we run these evals in a batch on a spot instance or slower Azure Functions? Research task.

## Low Priority
- Offline handling - Store unsent requests and play them back once connectivity is restored. This should be relatively easy.

- Suggested eating times and amounts - Based on learned behavior and weight loss goals. Need to think and design what this feature even is. Is it notifications? Is it linear regressions on the user's chart data? Research task.

- Fine-tuned small language model - To do all the analysis on the device. Can make calls to the LLM if SLM can't figure it out or needs function calling (search). This needs research.

