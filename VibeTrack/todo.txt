handle todo list tasks. Research tasks dont need implementations, but should include guidance and reommendations

# VibeTrack TODO List

## High Priority
- Fix web search tool -
How web search works

When you add the web search tool to your API request:

    Claude decides when to search based on the prompt.
    The API executes the searches and provides Claude with the results. This process may repeat multiple times throughout a single request.
    At the end of its turn, Claude provides a final response with cited sources.

​
How to use web search


Provide the web search tool in your API request:
typescript example from the web:

import { Anthropic } from '@anthropic-ai/sdk';

const anthropic = new Anthropic();

async function main() {
  const response = await anthropic.messages.create({
    model: "claude-opus-4-1-20250805",
    max_tokens: 1024,
    messages: [
      {
        role: "user",
        content: "How do I update a web app to TypeScript 5.5?"
      }
    ],
    tools: [{
      type: "web_search_20250305",
      name: "web_search",
      max_uses: 5
    }]
  });

  console.log(response);
}

main().catch(console.error);

​
Tool definition

The web search tool supports the following parameters:
JSON

{
  "type": "web_search_20250305",
  "name": "web_search",

  // Optional: Limit the number of searches per request
  "max_uses": 5,

  // Optional: Only include results from these domains
  "allowed_domains": ["example.com", "trusteddomain.org"],

  // Optional: Never include results from these domains
  "blocked_domains": ["untrustedsource.com"],

  // Optional: Localize search results
  "user_location": {
    "type": "approximate",
    "city": "San Francisco",
    "region": "California",
    "country": "US",
    "timezone": "America/Los_Angeles"
  }
}


- Log user inputs and AI outputs - All of them. Have a place in the app to view it (small button, used for development to quickly see logs about what's going on).

- Edit food items with swipe gesture. For example: 'Actually it was a large fries' or 'Add 100 more calories' - If you slide from left to right you should get a button to edit. the button when clicked will start recording.you should be able to speak to edit. The new data and old data are both sent to the AI API. When clicked, immediatly start the recording, no need to ask for confirmation. The record button turns into a button to stop recording. then send the success mesasge with details which could be like a toast message or something. 
- Update all the ui copy to have better vibes. pull it all out into a file for all the text that gets displayed to the user so we can see it all in one place. The tone we're going for is somwhere btween tech bro and gen z slag. Its all about the vibes.
- additional way to navigate app. swipe gesture beteen views. so you can move from track view to enties view by swiping the screen from right to left.

## Medium Priority
- reserach task. Semantic caching for responses - Users will most likely eat the same things multiple times. Need to design this to flesh out the idea. There are a couple papers worth reading on this because semantic caching is storing the user's intent not just the hashed input verbatim. So "avocado toast" and "toast with avocado" are both the same and a cache hit. Anthropic has prompt caching, but is invalidated after 5 minutes. I would rather have something like a two-layer space-constrained cache. L1 would be smaller and per user, and L2 would be app-wide and larger. If both miss, then I guess go ask the LLM :)

- Cloud storage for user data/telemetry - Need to set up a cloud solution for receiving and analyzing telemetry. User I/O, failure rate, edit rate, user sentiment (frustrated, etc). Considering Azure Event Hubs and Service Bus since I have some Azure credits to use. Building it out with some Bicep declarative IaC would be good. Give instructions on setting this up with azure, i dont remember how to do it. I have 150 dollar credit per month to play with.

- Store input/output for AI responses - Evaluate those and make sure they are not deviating. Create the curated dataset based on if they are good or not, then train the SLM to check all responses and report success metrics. Can we run these evals in a batch on a spot instance or slower Azure Functions? Research task.

## Low Priority
- Offline handling - Store unsent requests and play them back once connectivity is restored. This should be relatively easy.

- Suggested eating times and amounts - Based on learned behavior and weight loss goals. Need to think and design what this feature even is. Is it notifications? Is it linear regressions on the user's chart data? Research task.

- Fine-tuned small language model - To do all the analysis on the device. Can make calls to the LLM if SLM can't figure it out or needs function calling (search). This needs research.

